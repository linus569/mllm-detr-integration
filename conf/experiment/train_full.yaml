# @package _global_
defaults:
  - /dataset@train_dataset: coco_train
  - /dataset@val_dataset: coco_val
  - /dataset@test_dataset: coco_test
  - /image_encoder: siglip

name: train_full
main_dir: "/u/home/salzmann/Documents/dev/master-thesis/"

model_name: 'lmms-lab/llava-onevision-qwen2-0.5b-si'
checkpoint_dir: '/u/home/salzmann/Documents/dev/master-thesis/checkpoints'

batch_size: 2
total_batch_size: 128 # tbs/bs = grad acum steps
num_samples: null # use full dataset
val_num_samples: 100
val_freq: 20000
print_freq: 50
epochs: 5
lr: 1e-4 #5e-5
warmup_ratio: 0.05
weight_decay: null # not used
max_grad_norm: 1.
max_tokens: 6400
pad_to_multiple_of: 128

temperature: 0.6
use_amp: true
torch_dtype: 'bfloat16' #none, float16 #bfloat16 error when using *16 because grad_scale works with *32

num_coordinate_bins: 100 #one for every pixel

# precompute
use_precompute: true # on eval double as fast on mac than without precompute
precompute_path: 'precomputed_img_siglip_bs2_bfloat16.hdf5'
precompute_batch_size: 2

# stage 1
bbox_ordering: none
freeze_model: false
detr_loss: true
num_query_tokens: 100
add_detr_layers: true